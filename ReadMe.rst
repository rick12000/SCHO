SCHO
========

Implementation of a conformal based sequential hyperparameter optimizer, as described in: `<https://arxiv.org/ftp/arxiv/papers/2207/2207.03017.pdf>`_

Sequential Conformal Hyperparameter Optimization (SCHO) tools in this library can:

* Perform hyperparameter tuning of convolutional and feed forward neural networks using dependant scikit-learn and tensorflow packages.

* Optimize parameters for both classification and regression problems.

* Provide support for a wide range of sequential point estimators (Gradient Boosted Machines, Random Forest, Gaussian Processes, secondary Neural Networks).

* Provide support for a wide range of sequential variance estimators (proximity based, linear MAD, Random Forest MAD, linear quantile estimators, boosted quantile estimators).

This repository is a work in progress and is currently built for simulation purposes only in relation to the creation of its source paper, but further work is planned to turn it into a package.

Documentation
=============

To be included in future commits.

Contact
=============

For enquiries please contact r.doyle.edu@gmail.com